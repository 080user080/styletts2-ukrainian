import os
import time
import threading
import gradio as gr
import soundfile as sf
from app_multi_novuj_vocoder import synthesize as synthesize_sync, prompts_list

OUTPUT_DIR = "output_audio"

# Dummy progress to bypass gr.Progress inside vocoder
class NoProgress:
    def tqdm(self, iterable):
        return iterable

# –†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
# –ó–∞–ª–∏—à–∞—î–º–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É –¥–æ–≤–∂–∏–Ω—É –¥–ª—è —á–∞—Å—Ç–∏–Ω–∏

#GPT  49000
def split_to_parts(text, max_chars=10000):
    # –°–ø–æ—á–∞—Ç–∫—É —Ä–æ–∑–±–∏–≤–∞—î–º–æ –ø–æ –ø–æ–¥–≤—ñ–π–Ω–∏—Ö –µ–Ω—Ç–µ—Ä–∞—Ö
    paragraphs = text.split("\n\n")
    parts = []

    for para in paragraphs:
        para = para.strip()
        if not para:
            continue

        # –Ø–∫—â–æ –∞–±–∑–∞—Ü –∫–æ—Ä–æ—Ç—à–∏–π –∑–∞ max_chars ‚Äî –¥–æ–¥–∞—î–º–æ –æ–¥—Ä–∞–∑—É
        if len(para) <= max_chars:
            parts.append(para)
        else:
            # –Ü–Ω–∞–∫—à–µ —Ä–æ–∑–±–∏–≤–∞—î–º–æ –∞–±–∑–∞—Ü –ø–æ —Ä–æ–∑–¥—ñ–ª–æ–≤–∏—Ö –∑–Ω–∞–∫–∞—Ö
            buffer = ""
            for char in para:
                buffer += char
                if char in ".?!:;" and len(buffer) >= max_chars:
                    parts.append(buffer.strip())
                    buffer = ""
            if buffer.strip():
                parts.append(buffer.strip())

    return parts

# —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —á–∞—Å—É –≤ –≥–æ–¥–∏–Ω–∏:—Ö–≤–∏–ª–∏–Ω–∏:—Å–µ–∫—É–Ω–¥–∏
def format_hms(seconds):
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    return f"{h:02}:{m:02}:{s:02}"

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è batch-–æ–∑–≤—É—á–µ–Ω–Ω—è –∑ –ø—Ä–æ–≥—Ä–µ—Å–æ–º —ñ –≤–∏–≤–µ–¥–µ–Ω–Ω—è–º –Ω–æ–º–µ—Ä–∞ —á–∞—Å—Ç–∏–Ω–∏

def batch_synthesize(file_path, speed, model_name, speaker, save_option):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    global_start = time.time()
    first_part_start = None
    last_part_end = None

    with open(file_path, 'r', encoding='utf-8') as f:
        text = f.read()

    parts = split_to_parts(text)
    total_parts = len(parts)
    times_per_part = []

    for idx, chunk in enumerate(parts, start=1):
        part_start = time.time()
        if first_part_start is None:
            first_part_start = part_start

        # –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        start_str = time.strftime('%H:%M:%S', time.localtime(first_part_start))
        prev_end_str = time.strftime('%H:%M:%S', time.localtime(last_part_end)) if last_part_end else '---'

        result = {}
        def run_synth():
            try:
                sr, audio_np = synthesize_sync(
                    model_name, chunk, speed,
                    voice_name=(speaker or None),
                    progress=NoProgress()
                )
                result['sr'] = sr
                result['audio'] = audio_np
            except Exception as e:
                result['error'] = str(e)

        synth_thread = threading.Thread(target=run_synth)
        synth_thread.start()

        # –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–∞–π–º–µ—Ä–∞ —ñ –ø—Ä–æ–≥–Ω–æ–∑—É –ø—ñ–¥ —á–∞—Å —Å–∏–Ω—Ç–µ–∑—É
        while synth_thread.is_alive():
            now = time.time()
            elapsed = int(now - global_start)
            elapsed_str = f"{elapsed} —Å–µ–∫ --- {format_hms(elapsed)}"  # <-- –∑–º—ñ–Ω–∞ —Ç—É—Ç
            if times_per_part:
                avg_time = sum(times_per_part) / len(times_per_part)
                est_total_time = avg_time * total_parts
                est_finish_ts = global_start + est_total_time
                est_finish_str = time.strftime('%H:%M:%S', time.localtime(est_finish_ts))
                rem_secs = int(est_finish_ts - now)
                rem_min, rem_sec = divmod(rem_secs, 60)
                rem_text = f"–¥–æ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è –∑–∞–ª–∏—à–∏–ª–æ—Å—è {rem_min} —Ö–≤ {rem_sec} —Å–µ–∫"
            else:
                est_finish_str = '–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫...'
                rem_text = '–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫...'

            yield (
                None,
                gr.update(value=idx, maximum=total_parts),
                elapsed_str,  # <-- –∑–∞–º—ñ–Ω–∞
                #f"{elapsed} —Å–µ–∫", # —Å—Ç–∞—Ä–µ –∑–Ω–∞—á–µ–Ω–Ω—è
                start_str,
                prev_end_str,
                est_finish_str,
                rem_text
            )
            time.sleep(1)

        synth_thread.join()
        if 'error' in result:
            raise RuntimeError(f"Synthesis error: {result['error']}")

        # –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
        sr = result['sr']
        audio_np = result['audio']
        audio_filename = os.path.join(OUTPUT_DIR, f"part_{idx:03}.wav")
        sf.write(audio_filename, audio_np, sr)
        if save_option == '–ó–±–µ—Ä–µ–≥—Ç–∏ –≤—Å—ñ —á–∞—Å—Ç–∏–Ω–∏ –æ–∑–≤—É—á–µ–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É':
            txt_filename = os.path.join(OUTPUT_DIR, f"part_{idx:03}.txt")
            with open(txt_filename, 'w', encoding='utf-8') as txt_file:
                txt_file.write(chunk)

        # —Ñ—ñ–Ω–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è —á–∞—Å—Ç–∏–Ω–∏
        part_end = time.time()
        last_part_end = part_end
        end_prev_str = time.strftime('%H:%M:%S', time.localtime(part_end))
        times_per_part.append(part_end - part_start)

        now = part_end
        elapsed = int(now - global_start)
        avg_time = sum(times_per_part) / len(times_per_part)
        est_total_time = avg_time * total_parts
        est_finish_ts = global_start + est_total_time
        est_finish_str = time.strftime('%H:%M:%S', time.localtime(est_finish_ts))
        rem_secs = int(est_finish_ts - now)
        rem_min, rem_sec = divmod(rem_secs, 60)
        rem_text = f"–¥–æ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è –∑–∞–ª–∏—à–∏–ª–æ—Å—è {rem_min} —Ö–≤ {rem_sec} —Å–µ–∫"

        yield (
            audio_filename,
            gr.update(value=idx, maximum=total_parts),
            f"{elapsed} —Å–µ–∫",
            start_str,
            end_prev_str,
            est_finish_str,
            rem_text
        )

    # –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö —á–∞—Å—Ç–∏–Ω
    global_end = time.time()
    mins, secs = divmod(global_end - global_start, 60)
    print(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û –æ–± {time.strftime('%H:%M:%S', time.localtime(global_end))}")
    print(f"‚è±Ô∏è –ó–∞–≥–∞–ª—å–Ω–∏–π —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {int(mins)} —Ö–≤ {int(secs)} —Å–µ–∫")

# Gradio UI
save_choices = ['–ó–±–µ—Ä–µ–≥—Ç–∏ –≤—Å—ñ —á–∞—Å—Ç–∏–Ω–∏ –æ–∑–≤—É—á–µ–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É', '–ë–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è']

with gr.Blocks(title="Batch TTS –∑ –ü—Ä–æ–≥—Ä–µ—Å–æ–º") as demo:
    with gr.Tabs():
        with gr.TabItem('Single speaker'):
            file_input = gr.File(label='üìÑ –û–±–µ—Ä—ñ—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª', type='filepath')
            speed = gr.Slider(0.7, 1.3, value=0.88, label='üöÄ –®–≤–∏–¥–∫—ñ—Å—Ç—å')
            model_name = gr.Text(value='single', visible=False)
            speaker_dummy = gr.Text(value='', visible=False)
            save_option = gr.Radio(choices=save_choices, label='–û–ø—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è', value=save_choices[1])
            btn = gr.Button('‚ñ∂ –†–æ–∑–ø–æ—á–∞—Ç–∏ –æ–∑–≤—É—á–µ–Ω–Ω—è')
            output_audio = gr.Audio(label='üîä –ü–æ—Ç–æ—á–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞', type='filepath')
            part_slider = gr.Slider(label='–ß–∞—Å—Ç–∏–Ω–∞ —Ç–µ–∫—Å—Ç—É', minimum=1, maximum=1, step=1, value=1, interactive=False)
            with gr.Row():
                timer_text = gr.Textbox(label="‚è±Ô∏è –í—ñ–¥–ª—ñ–∫ —á–∞—Å—É (—Å–µ–∫)", value="0", interactive=False)
                start_time_text = gr.Textbox(label="–ü–æ—á–∞—Ç–æ–∫ –æ–∑–≤—É—á–µ–Ω–Ω—è", interactive=False)
                end_time_text = gr.Textbox(label="–ó–∞–∫—ñ–Ω—á–µ–Ω–Ω—è –æ–∑–≤—É—á–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó —á–∞—Å—Ç–∏–Ω–∏", interactive=False)
            with gr.Row():
                est_end_time_text = gr.Textbox(label="–ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è", interactive=False)
                remaining_time_text = gr.Textbox(label="–ß–∞—Å –¥–æ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è", interactive=False)
            btn.click(
                fn=batch_synthesize,
                inputs=[file_input, speed, model_name, speaker_dummy, save_option],
                outputs=[output_audio, part_slider, timer_text, start_time_text, end_time_text, est_end_time_text, remaining_time_text],
                show_progress=False
            )
        with gr.TabItem('Multi speaker'):
            file_input_m = gr.File(label='üìÑ –û–±–µ—Ä—ñ—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∏–π —Ñ–∞–π–ª', type='filepath')
            speed_m = gr.Slider(0.7, 1.3, value=0.88, label='üöÄ –®–≤–∏–¥–∫—ñ—Å—Ç—å')
            speaker = gr.Dropdown(label="–ì–æ–ª–æ—Å:", choices=prompts_list, value=prompts_list[0])
            model_name_m = gr.Text(value='multi', visible=False)
            save_option_m = gr.Radio(choices=save_choices, label='–û–ø—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è', value=save_choices[1])
            btn_m = gr.Button('‚ñ∂ –†–æ–∑–ø–æ—á–∞—Ç–∏ –æ–∑–≤—É—á–µ–Ω–Ω—è')
            output_audio_m = gr.Audio(label='üîä –ü–æ—Ç–æ—á–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞', type='filepath')
            part_slider_m = gr.Slider(label='–ß–∞—Å—Ç–∏–Ω–∞ —Ç–µ–∫—Å—Ç—É', minimum=1, maximum=1, step=1, value=1, interactive=False)
            with gr.Row():
                timer_text_m = gr.Textbox(label="‚è±Ô∏è –í—ñ–¥–ª—ñ–∫ —á–∞—Å—É (—Å–µ–∫)", value="0", interactive=False)
                start_time_text_m = gr.Textbox(label="–ü–æ—á–∞—Ç–æ–∫ –æ–∑–≤—É—á–µ–Ω–Ω—è", interactive=False)
                end_time_text_m = gr.Textbox(label="–ó–∞–∫—ñ–Ω—á–µ–Ω–Ω—è –æ–∑–≤—É—á–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó —á–∞—Å—Ç–∏–Ω–∏", interactive=False)
            with gr.Row():
                est_end_time_text_m = gr.Textbox(label="–ü—Ä–æ–≥–Ω–æ–∑ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è", interactive=False)
                remaining_time_text_m = gr.Textbox(label="–ß–∞—Å –¥–æ –∑–∞–∫—ñ–Ω—á–µ–Ω–Ω—è", interactive=False)
            btn_m.click(
                fn=batch_synthesize,
                inputs=[file_input_m, speed_m, model_name_m, speaker, save_option_m],
                outputs=[output_audio_m, part_slider_m, timer_text_m, start_time_text_m, end_time_text_m, est_end_time_text_m, remaining_time_text_m],
                show_progress=False
            )
if __name__ == '__main__':
    demo.queue().launch()
