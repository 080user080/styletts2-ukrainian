"""
–†–æ–∑—à–∏—Ä–µ–Ω–∏–π Gradio UI –¥–ª—è TTS –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é Multi Dialog, SFX —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å —Å–ø—ñ–∫–µ—Ä—ñ–≤.
–Ü–Ω—Ç–µ–≥—Ä—É—î—Ç—å—Å—è —É –º–æ–¥—É–ª—å–Ω—É —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ app_context.
"""

import os
import time
import re
import unicodedata
import traceback
import uuid
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, Iterable, List, Sequence, Tuple
from datetime import datetime

import gradio as gr
import numpy as np
import soundfile as sf
import yaml
from scipy import signal
import math

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏
SPEAKER_MAX = 30
PROGRESS_POLL_INTERVAL = 1.0
DEFAULT_SPEED_CODE = 0.88
OUTPUT_DIR_BASE = "output_audio"

# –ì–ª–æ–±–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ (–±—É–¥—É—Ç—å —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –≤ initialize)
_app_context = None
_tts_engine = None
_logger = None
SFX_CONFIG = {}
DEFAULT_SPEED = DEFAULT_SPEED_CODE


def initialize(app_context: Dict[str, Any]) -> Dict[str, Any]:
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–¥—É–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–æ–≥–æ Gradio UI"""
    global _app_context, _tts_engine, _logger, SFX_CONFIG, DEFAULT_SPEED
    
    _app_context = app_context
    _logger = app_context.get('logger')
    _tts_engine = app_context.get('tts_engine')
    
    if not _tts_engine:
        raise RuntimeError("TTS Engine –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ app_context")
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥ SFX
    SFX_CONFIG = _load_sfx_config()
    DEFAULT_SPEED = float(SFX_CONFIG.get("default_speed", DEFAULT_SPEED_CODE))
    
    _logger.info("üé® –†–æ–∑—à–∏—Ä–µ–Ω–∏–π Gradio UI —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    
    # –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ç–∞ –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    demo = create_advanced_interface()
    
    return {
        'demo': demo,
        'launch': lambda: demo.queue().launch()
    }


# ============================================================================
# –£–¢–ò–õ–Ü–¢–ò –¢–ê –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á
# ============================================================================

def make_session_output_dir(base: str = OUTPUT_DIR_BASE) -> str:
    """–°—Ç–≤–æ—Ä—é—î –ø–∞–ø–∫—É –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ—ó —Å–µ—Å—ñ—ó –∑ timestamp"""
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    out = os.path.join(base, ts)
    try:
        os.makedirs(out, exist_ok=True)
    except Exception:
        out = base
        os.makedirs(out, exist_ok=True)
    return out


OUTPUT_DIR = make_session_output_dir()


def _load_sfx_config(path: str = "sfx.yaml") -> dict:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é SFX –∑ YAML"""
    cfg = {"normalize_dbfs": -16, "sounds": {}}
    candidates = [
        os.path.join(os.getcwd(), "sfx.yaml"),
        os.path.join(os.getcwd(), "sound", "sfx.yaml"),
    ]
    found = None
    for p in candidates:
        if os.path.exists(p):
            found = p
            break
    if not found:
        return cfg
    try:
        with open(found, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
            if isinstance(data, dict):
                cfg.update(data)
        cfg["_cfg_dir"] = os.path.dirname(found)
    except Exception:
        pass
    return cfg


def get_sfx_config() -> dict:
    """–î–∏–Ω–∞–º—ñ—á–Ω–µ —á–∏—Ç–∞–Ω–Ω—è sfx.yaml"""
    return _load_sfx_config()


def format_hms(seconds):
    """–§–æ—Ä–º–∞—Ç—É—î —Å–µ–∫—É–Ω–¥–∏ —É HH:MM:SS"""
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    return f"{h:02}:{m:02}:{s:02}"


def normalize_text(s: str) -> str:
    """–ù–æ—Ä–º–∞–ª—ñ–∑—É—î —Ç–µ–∫—Å—Ç, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ '+'"""
    if not isinstance(s, str):
        return s
    s = unicodedata.normalize("NFKC", s).replace("\ufeff", "")
    s = (s.replace("'","'").replace(" º","'").replace(" ª","'").replace(" π","'")
           .replace("‚Äî","-").replace("‚Äì","-").replace("‚àí","-"))
    out = []
    for ch in s:
        if ch == '+':
            out.append(ch)
            continue
        cat = unicodedata.category(ch)
        if cat in ("Cf","Cc") and ch not in ("\n","\r","\t"):
            continue
        out.append(ch)
    s = "".join(out)
    s = s.replace("\u00A0", " ")
    s = re.sub(r"\s*\n\s*", "\n", s)
    return s


# ============================================================================
# PARSER –ü–û–î–Ü–ô –°–¶–ï–ù–ê–†–Ü–Æ
# ============================================================================

def parse_script_events(text: str, voices_flat: List[str]) -> List[dict]:
    """
    –ü–∞—Ä—Å–∏—Ç—å —Å—Ü–µ–Ω–∞—Ä—ñ–π —É —Å–ø–∏—Å–æ–∫ –ø–æ–¥—ñ–π (voice/sfx).
    
    –§–æ—Ä–º–∞—Ç:
    - #gN[_slow|_fast|_slowNN|_fastNN]: —Ç–µ–∫—Å—Ç -> voice –ø–æ–¥—ñ—è
    - #<sfx_id> -> sfx –ø–æ–¥—ñ—è
    """
    events: List[dict] = []
    if not isinstance(text, str):
        return events
    
    lines = normalize_text(text).splitlines()
    voice_pat = re.compile(r"^#g\s*([1-9]|[12][0-9]|30)(?:_((?:slow|fast)(?:\d{1,3})?))?\s*:??\s+(.*)$", re.IGNORECASE)
    sfx_pat = re.compile(r'^#([A-Za-z0-9_]+)\s*$', re.IGNORECASE)
    
    for line_no, raw_ln in enumerate(lines, start=1):
        ln = raw_ln.strip()
        if not ln:
            continue
        
        # Voice –ø–æ–¥—ñ—è
        m_voice = voice_pat.match(ln)
        if m_voice:
            g_str, suffix, text_body = m_voice.groups()
            g_num = int(g_str)
            suffix = suffix.lower() if suffix else ""
            if not text_body.strip():
                raise RuntimeError(f"–ü–æ—Ä–æ–∂–Ω—ñ–π —Ç–µ–∫—Å—Ç –ø—ñ—Å–ª—è —Ç–µ–≥–∞ #g{g_num} –Ω–∞ —Ä—è–¥–∫—É {line_no}")
            if g_num < 1 or g_num > SPEAKER_MAX:
                raise RuntimeError(f"–ù–µ–ø—Ä–∏–ø—É—Å—Ç–∏–º–∏–π –Ω–æ–º–µ—Ä —Å–ø—ñ–∫–µ—Ä–∞: {g_num} –Ω–∞ —Ä—è–¥–∫—É {line_no}")
            events.append({"type": "voice", "g": g_num, "suffix": suffix, "text": text_body})
            continue
        
        # SFX –ø–æ–¥—ñ—è
        m_sfx = sfx_pat.match(ln)
        if m_sfx:
            sfx_id = m_sfx.group(1)
            if sfx_id not in SFX_CONFIG.get('sounds', {}):
                raise RuntimeError(f"SFX '{sfx_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É sfx.yaml (—Ä—è–¥–æ–∫ {line_no})")
            events.append({"type": "sfx", "id": sfx_id, "params": {}})
            continue
        
        # –ö–æ–º–µ–Ω—Ç–∞—Ä
        if ln.startswith('#'):
            continue
        
        # –ó–≤–∏—á–∞–π–Ω–∏–π —Ç–µ–∫—Å—Ç -> g1
        events.append({"type": "voice", "g": 1, "suffix": "", "text": ln})
    
    return events


# ============================================================================
# –û–ë–ß–ò–°–õ–ï–ù–ù–Ø –®–í–ò–î–ö–û–°–¢–Ü
# ============================================================================

def _compute_speed_effective(g_num: int, suffix: str, speeds_flat: List[float], ignore_speed: bool) -> float:
    """–û–±—á–∏—Å–ª—é—î –µ—Ñ–µ–∫—Ç–∏–≤–Ω—É —à–≤–∏–¥–∫—ñ—Å—Ç—å –¥–ª—è voice –ø–æ–¥—ñ—ó"""
    if ignore_speed:
        return DEFAULT_SPEED
    
    suf = suffix.lower() if suffix else ""
    
    if suf == 'slow':
        return 0.80
    if suf == 'fast':
        return 1.20
    if suf.startswith('slow') and len(suf) > 4:
        try:
            return float(suf[4:]) / 100.0
        except Exception:
            pass
    if suf.startswith('fast') and len(suf) > 4:
        try:
            return float(suf[4:]) / 100.0
        except Exception:
            pass
    
    if 1 <= g_num <= len(speeds_flat):
        try:
            return float(speeds_flat[g_num - 1])
        except Exception:
            pass
    
    return DEFAULT_SPEED


# ============================================================================
# –°–ò–ù–¢–ï–ó –¢–ê –û–ë–†–û–ë–ö–ê –ê–£–î–Ü–û
# ============================================================================

def _synthesize_chunk(chunk: str, voice: str | None, speed: float) -> Tuple[int, np.ndarray]:
    """–°–∏–Ω—Ç–µ–∑—É—î –æ–¥–∏–Ω —à–º–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç—É —á–µ—Ä–µ–∑ TTS Engine"""
    global _tts_engine
    
    if not _tts_engine:
        raise RuntimeError("TTS Engine –Ω–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    
    # –í–∏–∫–ª–∏–∫–∞—î–º–æ –º–µ—Ç–æ–¥ —Å–∏–Ω—Ç–µ–∑—É –∑ TTS Engine
    result = _tts_engine.synthesize(
        text=chunk,
        voice=voice,
        speed=speed
    )
    
    return result['sample_rate'], result['audio']


def _load_and_process_sfx(sfx_id: str, target_sr: int) -> Tuple[int, np.ndarray]:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ç–∞ –æ–±—Ä–æ–±–ª—è—î SFX —Ñ–∞–π–ª"""
    cfg_all = get_sfx_config()
    cfg = cfg_all.get('sounds', {}).get(sfx_id)
    if not cfg:
        raise RuntimeError(f"SFX –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –≤—ñ–¥—Å—É—Ç–Ω—è –¥–ª—è '{sfx_id}'")
    
    src_file = cfg.get('file')
    if not src_file:
        raise RuntimeError(f"–§–∞–π–ª –¥–ª—è SFX '{sfx_id}' –Ω–µ –≤–∫–∞–∑–∞–Ω–∏–π")
    
    # –ü–æ—à—É–∫ —Ñ–∞–π–ª—É
    possible_paths = [
        src_file,
        os.path.join(os.getcwd(), src_file),
        os.path.join(OUTPUT_DIR, src_file),
    ]
    cfg_dir = cfg_all.get("_cfg_dir")
    if cfg_dir:
        possible_paths.append(os.path.join(cfg_dir, src_file))
        possible_paths.append(os.path.join(cfg_dir, "sound", src_file))
    
    audio_path = None
    for p in possible_paths:
        if p and os.path.exists(p):
            audio_path = p
            break
    
    if not audio_path:
        raise RuntimeError(f"–§–∞–π–ª SFX '{src_file}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ (id: '{sfx_id}')")
    
    # –ß–∏—Ç–∞–Ω–Ω—è –∞—É–¥—ñ–æ
    data, sr = sf.read(audio_path)
    data = np.asarray(data, dtype=np.float32)
    if data.ndim > 1:
        data = data.mean(axis=1)
    
    # –†–µ—Å–µ–º–ø–ª
    if sr != target_sr:
        duration = data.shape[0] / sr
        target_len = int(round(duration * target_sr))
        if target_len <= 0:
            target_len = 1
        data = signal.resample(data, target_len)
        sr = target_sr
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
    normalize_dbfs = cfg_all.get('normalize_dbfs')
    if cfg.get('normalize') is False:
        normalize_dbfs = None
    
    rms = math.sqrt(np.mean(data ** 2)) if data.size else 0.0
    if rms > 0:
        current_dbfs = 20 * math.log10(rms)
    else:
        current_dbfs = -float('inf')
    
    total_gain_db = float(cfg.get('gain_db', 0.0))
    if normalize_dbfs is not None and current_dbfs > -float('inf'):
        total_gain_db += (float(normalize_dbfs) - current_dbfs)
    
    gain_factor = 10.0 ** (total_gain_db / 20.0)
    data = data * gain_factor
    
    # Fade in/out
    fade_ms = 30
    fade_len = int(sr * fade_ms / 1000.0)
    fade_len = max(fade_len, 1)
    
    if data.size >= fade_len:
        ramp_in = np.linspace(0.0, 1.0, fade_len, dtype=data.dtype)
        data[:fade_len] *= ramp_in
        ramp_out = np.linspace(1.0, 0.0, fade_len, dtype=data.dtype)
        data[-fade_len:] *= ramp_out
    
    return sr, data


# ============================================================================
# BATCH –°–ò–ù–¢–ï–ó –ó –ü–û–î–Ü–Ø–ú–ò
# ============================================================================

def batch_synthesize_dialog_events(
    text_input: str | None,
    file_path: str | None,
    speeds_flat: list,
    voices_flat: list,
    save_option,
    ignore_speed: bool = False,
) -> Iterable:
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ–∑—É –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –ø–æ–¥—ñ–π"""
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    global_start = time.time()
    
    # –ß–∏—Ç–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
    if text_input and text_input.strip():
        text = text_input
    elif file_path:
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()
    else:
        raise RuntimeError("–ù–µ–º–∞—î —Ç–µ–∫—Å—Ç—É –¥–ª—è –æ–∑–≤—É—á–µ–Ω–Ω—è")
    
    start_time_str = time.strftime('%H:%M:%S', time.localtime(global_start))
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–¥—ñ–π
    try:
        events = parse_script_events(text, voices_flat)
    except Exception as e:
        if _logger:
            _logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
        raise
    
    total_parts = max(1, len(events))
    times_per_part: List[float] = []
    warnings: List[str] = []
    base_sr: int | None = None
    
    voice_map = {i + 1: (voices_flat[i] if i < len(voices_flat) else None) for i in range(SPEAKER_MAX)}
    
    # –ü–æ—á–∞—Ç–∫–æ–≤–∏–π yield
    yield (
        None,
        gr.update(value=1, maximum=total_parts, interactive=False),
        "0 —Å–µ–∫",
        start_time_str,
        "",
        "–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫...",
        "",
        gr.update(value=0, maximum=total_parts, interactive=False),
    )
    
    # –û–±—Ä–æ–±–∫–∞ –ø–æ–¥—ñ–π
    for idx, event in enumerate(events, start=1):
        part_start = time.time()
        
        if event.get('type') == 'voice':
            g_num = event.get('g')
            suffix = event.get('suffix', '')
            text_body = event.get('text', '')
            voice_name = voice_map.get(g_num, None)
            speed_eff = _compute_speed_effective(g_num, suffix, speeds_flat, ignore_speed)
            
            if not ignore_speed and (speed_eff < 0.7 or speed_eff > 1.3):
                warnings.append(f'–®–≤–∏–¥–∫—ñ—Å—Ç—å –ø–æ–∑–∞ –º–µ–∂–∞–º–∏ –¥–ª—è #g{g_num}: {speed_eff:.2f}')
            if not voice_name:
                warnings.append(f'–ì–æ–ª–æ—Å –Ω–µ –≤–∫–∞–∑–∞–Ω–æ –¥–ª—è #g{g_num}')
            
            call_func = _synthesize_chunk
            call_args = (text_body, voice_name, speed_eff)
            extra_info = {
                "type": "voice",
                "g": g_num,
                "voice_name": voice_name,
                "speed_eff": speed_eff,
                "text_body": text_body,
            }
        
        elif event.get('type') == 'sfx':
            sfx_id = event.get('id')
            target_sr = base_sr if base_sr else 24000
            call_func = _load_and_process_sfx
            call_args = (sfx_id, target_sr)
            cfg = SFX_CONFIG.get('sounds', {}).get(sfx_id, {})
            extra_info = {
                "type": "sfx",
                "sfx_id": sfx_id,
                "file": cfg.get('file'),
            }
        else:
            warnings.append(f"–ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø –ø–æ–¥—ñ—ó: {event}")
            continue
        
        # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –∑ –ø—Ä–æ–≥—Ä–µ—Å–æ–º
        with ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(call_func, *call_args)
            
            while not future.done():
                now = time.time()
                elapsed = int(now - global_start)
                elapsed_str = f"{elapsed} —Å–µ–∫ --- {format_hms(elapsed)}"
                est_finish_str = '–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫...'
                rem_text = '–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫...'
                
                if times_per_part:
                    avg_time = sum(times_per_part) / len(times_per_part)
                    est_total_time = avg_time * total_parts
                    est_finish_str = time.strftime('%H:%M:%S', time.localtime(global_start + est_total_time))
                    rem_secs = int(global_start + est_total_time - now)
                    rem_min, rem_sec = divmod(max(rem_secs, 0), 60)
                    rem_text = f"–∑–∞–ª–∏—à–∏–ª–æ—Å—å {rem_min} —Ö–≤ {rem_sec} —Å–µ–∫"
                
                yield (
                    None,
                    gr.update(value=idx, maximum=total_parts, interactive=False),
                    elapsed_str,
                    start_time_str,
                    None,
                    est_finish_str,
                    rem_text,
                    gr.update(value=max(idx - 1, 0), maximum=total_parts, interactive=False),
                )
                time.sleep(PROGRESS_POLL_INTERVAL)
            
            try:
                sr, audio_np = future.result()
            except Exception as e:
                if _logger:
                    _logger.error(f'–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —á–∞—Å—Ç–∏–Ω–∏ {idx}: {e}')
                raise
        
        if extra_info["type"] == "voice" and base_sr is None:
            base_sr = sr
        
        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        audio_filename = os.path.join(OUTPUT_DIR, f"part_{idx:03}.wav")
        sf.write(audio_filename, audio_np, sr)
        
        if save_option == '–ó–±–µ—Ä–µ–≥—Ç–∏ –≤—Å—ñ —á–∞—Å—Ç–∏–Ω–∏' and extra_info["type"] == "voice":
            txt_filename = os.path.join(OUTPUT_DIR, f"part_{idx:03}.txt")
            with open(txt_filename, 'w', encoding='utf-8') as f:
                f.write(extra_info["text_body"])
        
        part_end = time.time()
        times_per_part.append(part_end - part_start)
        
        end_time_str = time.strftime('%H:%M:%S', time.localtime(part_end))
        elapsed_seconds = int(part_end - global_start)
        elapsed_total = f"{elapsed_seconds} —Å–µ–∫ --- {format_hms(elapsed_seconds)}"
        
        yield (
            audio_filename,
            gr.update(value=idx, maximum=total_parts, interactive=False),
            elapsed_total,
            start_time_str,
            end_time_str,
            None,
            "",
            gr.update(value=idx, maximum=total_parts, interactive=False),
        )
    
    # –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è
    total_elapsed_secs = int(time.time() - global_start)
    total_formatted = format_hms(total_elapsed_secs)
    finish_time_str = time.strftime('%H:%M:%S', time.localtime(time.time()))
    
    if warnings and _logger:
        for w in warnings:
            _logger.warning(w)
    
    yield (
        None,
        gr.update(value=total_parts, maximum=total_parts, interactive=True),
        f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {total_elapsed_secs} —Å–µ–∫",
        start_time_str,
        finish_time_str,
        None,
        "",
        gr.update(value=total_parts, maximum=total_parts, interactive=False),
    )


# ============================================================================
# –°–¢–í–û–†–ï–ù–ù–Ø GRADIO –Ü–ù–¢–ï–†–§–ï–ô–°–£
# ============================================================================

def create_advanced_interface():
    """–°—Ç–≤–æ—Ä—é—î —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π Gradio —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    
    # –û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å—ñ–≤ –∑ TTS Engine
    speaker_choices = _tts_engine.get_available_voices() if _tts_engine else ["default"]
    
    with gr.Blocks(title="TTS Multi Dialog Advanced") as demo:
        gr.Markdown("# üéôÔ∏è TTS Multi Dialog - –†–æ–∑—à–∏—Ä–µ–Ω–∏–π —Ä–µ–∂–∏–º")
        
        with gr.Row():
            text_input = gr.Textbox(
                label='üìã –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–µ–Ω–Ω—è',
                lines=10,
                placeholder='#g1: –ü—Ä–∏–≤—ñ—Ç!\n#g2_fast: –Ø–∫ —Å–ø—Ä–∞–≤–∏?\n#sfx_bell\n#g1_slow: –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!'
            )
        
        with gr.Row():
            file_input = gr.File(label='üìÇ –ê–±–æ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª', type='filepath')
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –¥–ª—è 30 —Å–ø—ñ–∫–µ—Ä—ñ–≤
        voice_components = []
        speed_components = []
        
        with gr.Accordion("‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–ø—ñ–∫–µ—Ä—ñ–≤ #g1-#g3", open=True):
            with gr.Row():
                for i in range(1, 4):
                    with gr.Column():
                        voice_components.append(
                            gr.Dropdown(
                                label=f'–ì–æ–ª–æ—Å #g{i}',
                                choices=speaker_choices,
                                value=speaker_choices[0]
                            )
                        )
                        speed_components.append(
                            gr.Slider(0.7, 1.3, value=0.88, label=f'–®–≤–∏–¥–∫—ñ—Å—Ç—å #g{i}')
                        )
        
        with gr.Accordion("‚öôÔ∏è –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–ø—ñ–∫–µ—Ä–∏ #g4-#g30", open=False):
            for row_start in range(4, 31, 3):
                with gr.Row():
                    for i in range(row_start, min(row_start + 3, 31)):
                        with gr.Column():
                            voice_components.append(
                                gr.Dropdown(
                                    label=f'–ì–æ–ª–æ—Å #g{i}',
                                    choices=speaker_choices,
                                    value=speaker_choices[0],
                                    visible=False
                                )
                            )
                            speed_components.append(
                                gr.Slider(0.7, 1.3, value=0.88, label=f'–®–≤–∏–¥–∫—ñ—Å—Ç—å #g{i}', visible=False)
                            )
        
        with gr.Row():
            ignore_speed_chk = gr.Checkbox(label='–Ü–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ —à–≤–∏–¥–∫—ñ—Å—Ç—å', value=False)
            save_option = gr.Radio(
                choices=['–ó–±–µ—Ä–µ–≥—Ç–∏ –≤—Å—ñ —á–∞—Å—Ç–∏–Ω–∏', '–ë–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è'],
                label='–û–ø—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è',
                value='–ë–µ–∑ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è'
            )
        
        btn_start = gr.Button('‚ñ∂Ô∏è –†–æ–∑–ø–æ—á–∞—Ç–∏', variant='primary')
        
        # –ü—Ä–æ–≥—Ä–µ—Å
        with gr.Row():
            output_audio = gr.Audio(label='üîä –ü–æ—Ç–æ—á–Ω–∞ —á–∞—Å—Ç–∏–Ω–∞', type='filepath')
            part_slider = gr.Slider(label='–ß–∞—Å—Ç–∏–Ω–∞', minimum=1, maximum=1, step=1, value=1)
        
        with gr.Row():
            timer_text = gr.Textbox(label="‚è±Ô∏è –ß–∞—Å", value="0", interactive=False)
            start_time_text = gr.Textbox(label="–ü–æ—á–∞—Ç–æ–∫", interactive=False)
            end_time_text = gr.Textbox(label="–ö—ñ–Ω–µ—Ü—å", interactive=False)
        
        with gr.Row():
            parts_progress = gr.Slider(label='–ü—Ä–æ–≥—Ä–µ—Å', minimum=0, maximum=1, step=1, value=0)
            est_end_time_text = gr.Textbox(label="–ü—Ä–æ–≥–Ω–æ–∑", interactive=False)
            remaining_time_text = gr.Textbox(label="–ó–∞–ª–∏—à–∏–ª–æ—Å—å", interactive=False)
        
        # –°–∏–Ω—Ç–∞–∫—Å–∏—Å
        with gr.Accordion("üìñ –°–∏–Ω—Ç–∞–∫—Å–∏—Å —Ç–µ–≥—ñ–≤", open=False):
            gr.Markdown("""
            **–§–æ—Ä–º–∞—Ç –∫–æ–º–∞–Ω–¥:**
            - `#gN: —Ç–µ–∫—Å—Ç` ‚Äî –æ–∑–≤—É—á–∏—Ç–∏ –≥–æ–ª–æ—Å–æ–º ‚ÑñN (1-30)
            - `#gN_slow` / `#gN_fast` ‚Äî –ø–æ–≤—ñ–ª—å–Ω–æ (0.80) / —à–≤–∏–¥–∫–æ (1.20)
            - `#gN_slow95` / `#gN_fast110` ‚Äî —Ç–æ—á–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å (0.95 / 1.10)
            - `#<sfx_id>` ‚Äî –≤—Å—Ç–∞–≤–∏—Ç–∏ –∑–≤—É–∫–æ–≤–∏–π –µ—Ñ–µ–∫—Ç —ñ–∑ sfx.yaml
            
            **–ü—Ä–∏–∫–ª–∞–¥:**
            ```
            #g1: –ü—Ä–∏–≤—ñ—Ç, —è–∫ —Å–ø—Ä–∞–≤–∏?
            #g2_fast: –ß—É–¥–æ–≤–æ, –¥—è–∫—É—é!
            #sfx_bell
            #g1_slow95: –î–æ –∑—É—Å—Ç—Ä—ñ—á—ñ!
            ```
            """)
        
        # –û–±—Ä–æ–±–Ω–∏–∫ –∑–∞–ø—É—Å–∫—É
        def on_start(text_input, file_input, *flat_values):
            global SFX_CONFIG, DEFAULT_SPEED
            try:
                SFX_CONFIG = get_sfx_config()
                DEFAULT_SPEED = float(SFX_CONFIG.get("default_speed", DEFAULT_SPEED_CODE))
            except Exception as e:
                if _logger:
                    _logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ sfx.yaml: {e}")
            
            speeds = list(flat_values[:30])
            voices = list(flat_values[30:60])
            save_opt = flat_values[60] if len(flat_values) > 60 else None
            ignore_speed = bool(flat_values[61]) if len(flat_values) > 61 else False
            
            yield from batch_synthesize_dialog_events(
                text_input, file_input, speeds, voices, save_opt, ignore_speed
            )
        
        btn_start.click(
            fn=on_start,
            inputs=[text_input, file_input] + speed_components + voice_components + [save_option, ignore_speed_chk],
            outputs=[
                output_audio, part_slider, timer_text, start_time_text,
                end_time_text, est_end_time_text, remaining_time_text, parts_progress
            ],
            show_progress=False
        )
    
    return demo


# –ï–∫—Å–ø–æ—Ä—Ç –¥–ª—è –º–æ–¥—É–ª—å–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏
__all__ = ['initialize']
