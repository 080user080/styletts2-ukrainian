import gradio as gr
from typing import Optional, Dict, Any, Tuple
import numpy as np
import os
import time
from datetime import datetime
import soundfile as sf

class UIEventHandlers:
    """
    –û–±—Ä–æ–±–Ω–∏–∫–∏ –ø–æ–¥—ñ–π –¥–ª—è UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    """
    
    def __init__(self, core_instance=None):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –æ–±—Ä–æ–±–Ω–∏–∫—ñ–≤ –ø–æ–¥—ñ–π
        
        Args:
            core_instance: –ï–∫–∑–µ–º–ø–ª—è—Ä AdvancedUICore (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.core = core_instance
        print(f"üîÑ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ UIEventHandlers –∑ core: {core_instance is not None}")
    
    def text_changed_handler(self, text: str) -> Dict[str, Any]:
        """
        –û–±—Ä–æ–±–Ω–∏–∫ –∑–º—ñ–Ω–∏ —Ç–µ–∫—Å—Ç—É –≤ –ø–æ–ª—ñ –≤–≤–æ–¥—É
        """
        if not text or text.strip() == "":
            return {"value": "", "interactive": True}
        
        # –ú–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ core_instance –¥–ª—è –¥–æ–¥–∞—Ç–∫–æ–≤–æ—ó –ª–æ–≥—ñ–∫–∏
        if self.core:
            # –ù–∞–ø—Ä–∏–∫–ª–∞–¥, –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ–≤–∂–∏–Ω–∏ —Ç–µ–∫—Å—Ç—É —á–µ—Ä–µ–∑ core
            pass
        
        return {"value": text, "interactive": True}
    
    def save_audio_handler(self, audio: np.ndarray, samplerate: int, 
                          file_name: str = None, session_state: str = None) -> Optional[str]:
        """
        –ó–±–µ—Ä—ñ–≥–∞—î –∞—É–¥—ñ–æ—Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫
        
        Args:
            audio: –ê—É–¥—ñ–æ–¥–∞–Ω—ñ
            samplerate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—ó
            file_name: –Ü–º'—è —Ñ–∞–π–ª—É –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
            session_state: ID —Å–µ—Å—ñ—ó –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–∞–ø–∫–∏
            
        Returns:
            –®–ª—è—Ö –¥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É –∞–±–æ None –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ
        """
        try:
            from pathlib import Path
            
            # –û—Ç—Ä–∏–º–∞—Ç–∏ session_id –∑ core –∞–±–æ –∑ –∞—Ä–≥—É–º–µ–Ω—Ç—É
            if session_state:
                session_id = session_state
            elif self.core and hasattr(self.core, 'session_id'):
                session_id = self.core.session_id
            else:
                session_id = str(int(time.time()))
            
            print(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ –¥–ª—è —Å–µ—Å—ñ—ó: {session_id}")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è —Å–µ—Å—ñ—ó
            output_dir = Path("output_audio") / f"session_{session_id}"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # –ì–µ–Ω–µ—Ä—É—î–º–æ —ñ–º'—è —Ñ–∞–π–ª—É, —è–∫—â–æ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ
            if not file_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
                file_name = f"tts_output_{timestamp}.wav"
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞—É–¥—ñ–æ
            output_path = output_dir / file_name
            sf.write(str(output_path), audio, samplerate)
            
            print(f"‚úÖ –ê—É–¥—ñ–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_path}")
            return str(output_path)
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ: {e}")
            return None
    
    def apply_sfx_handler(self, audio: Optional[np.ndarray], sfx_type: str, 
                         intensity: float) -> Tuple[Optional[np.ndarray], str]:
        """
        –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –∑–≤—É–∫–æ–≤–∏—Ö –µ—Ñ–µ–∫—Ç—ñ–≤
        
        Args:
            audio: –í—Ö—ñ–¥–Ω–µ –∞—É–¥—ñ–æ
            sfx_type: –¢–∏–ø –µ—Ñ–µ–∫—Ç—É
            intensity: –Ü–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ñ—Å—Ç—å –µ—Ñ–µ–∫—Ç—É
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–æ–±—Ä–æ–±–ª–µ–Ω–µ –∞—É–¥—ñ–æ, –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è)
        """
        try:
            if audio is None:
                return None, "‚ùå –ù–µ–º–∞—î –∞—É–¥—ñ–æ –¥–ª—è –æ–±—Ä–æ–±–∫–∏"
            
            # –¢—É—Ç –º–∞—î –±—É—Ç–∏ –ª–æ–≥—ñ–∫–∞ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è SFX
            # –ù–∞—Ä–∞–∑—ñ –ø—Ä–æ—Å—Ç–æ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∞—É–¥—ñ–æ
            processed_audio = audio
            
            return processed_audio, f"‚úÖ SFX '{sfx_type}' –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ (—ñ–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ñ—Å—Ç—å: {intensity})"
            
        except Exception as e:
            return None, f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}"
    
    @staticmethod
    def normalize_audio(audio_data: np.ndarray) -> np.ndarray:
        """
        –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—É–¥—ñ–æ –¥–∞–Ω–∏—Ö
        """
        if audio_data is None or len(audio_data) == 0:
            return audio_data
        
        max_val = np.max(np.abs(audio_data))
        if max_val > 0:
            return audio_data / max_val * 0.9
        
        return audio_data
    
    @staticmethod
    def validate_audio_length(audio_data: np.ndarray, samplerate: int, 
                             max_duration_seconds: int = 30) -> Tuple[bool, str]:
        """
        –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ –∞—É–¥—ñ–æ
        """
        if audio_data is None:
            return False, "–ê—É–¥—ñ–æ –≤—ñ–¥—Å—É—Ç–Ω—î"
        
        duration = len(audio_data) / samplerate
        
        if duration > max_duration_seconds:
            return False, f"–ê—É–¥—ñ–æ –∑–∞–¥–æ–≤–≥–µ ({duration:.1f} —Å–µ–∫ > {max_duration_seconds} —Å–µ–∫)"
        
        return True, f"–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {duration:.1f} —Å–µ–∫"

# –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ—ó —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ
def save_audio_handler(audio, samplerate, session_state=None):
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π –≤–∏–∫–ª–∏–∫ –¥–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ—ó —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ"""
    handler = UIEventHandlers()
    return handler.save_audio_handler(audio, samplerate, session_state=session_state)

def text_changed_handler(text):
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π –≤–∏–∫–ª–∏–∫ –¥–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ—ó —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ"""
    handler = UIEventHandlers()
    result = handler.text_changed_handler(text)
    return gr.update(value=result["value"], interactive=result["interactive"])

def apply_sfx_handler(audio, sfx_type, intensity):
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–π –≤–∏–∫–ª–∏–∫ –¥–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ—ó —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ"""
    handler = UIEventHandlers()
    return handler.apply_sfx_handler(audio, sfx_type, intensity)

# –°—Ç–≤–æ—Ä—é—î–º–æ –≥–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É (–í–ê–ñ–õ–ò–í–û!)
event_handlers = UIEventHandlers()

if __name__ == "__main__":
    # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    print("–ú–æ–¥—É–ª—å UIEventHandlers –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ")
    
    # –¢–µ—Å—Ç —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó –∑ core
    test_core = type('TestCore', (), {})()
    test_core.session_id = "test_123"
    
    handler_with_core = UIEventHandlers(test_core)
    print(f"Handler –∑ core: {handler_with_core.core is not None}")
    
    # –¢–µ—Å—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
    test_audio = np.random.randn(44100)
    path = handler_with_core.save_audio_handler(test_audio, 44100)
    print(f"–¢–µ—Å—Ç–æ–≤–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {path}")